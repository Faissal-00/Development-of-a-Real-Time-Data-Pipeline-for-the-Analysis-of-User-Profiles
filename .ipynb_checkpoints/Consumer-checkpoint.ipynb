{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e27cc0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col, to_date, concat_ws, current_date, datediff, year\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from cassandra.cluster import Cluster\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"UserProfileAnalysis\")\\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.4,\"\n",
    "            \"com.datastax.spark:spark-cassandra-connector_2.12:3.2.0,\") \\\n",
    "        .config(\"spark.sql.streaming.forceDeleteTempCheckpointLocation\", \"true\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Define Kafka source configuration\n",
    "kafka_source = spark.readStream.format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"user_profiles\") \\\n",
    "    .load()\n",
    "\n",
    "# Define the schema for parsing JSON data\n",
    "json_schema = StructType([\n",
    "    StructField(\"gender\", StringType()),\n",
    "    StructField(\"name\", StructType([\n",
    "        StructField(\"title\", StringType()),\n",
    "        StructField(\"first\", StringType()),\n",
    "        StructField(\"last\", StringType())\n",
    "    ])),\n",
    "    StructField(\"location\", StructType([\n",
    "        StructField(\"street\", StructType([\n",
    "            StructField(\"number\", IntegerType()),\n",
    "            StructField(\"name\", StringType())\n",
    "        ])),\n",
    "        StructField(\"city\", StringType()),\n",
    "        StructField(\"state\", StringType()),\n",
    "        StructField(\"country\", StringType()),\n",
    "        StructField(\"postcode\", IntegerType())\n",
    "    ])),\n",
    "    StructField(\"email\", StringType()),\n",
    "    StructField(\"login\", StructType([\n",
    "        StructField(\"uuid\", StringType()),\n",
    "        StructField(\"username\", StringType()),\n",
    "    ])),\n",
    "    StructField(\"dob\", StructType([\n",
    "        StructField(\"date\", StringType()),\n",
    "        StructField(\"age\", IntegerType())\n",
    "    ])),\n",
    "    StructField(\"registered\", StructType([\n",
    "        StructField(\"date\", StringType()),\n",
    "        StructField(\"age\", IntegerType())\n",
    "    ])),\n",
    "    StructField(\"phone\", StringType()),\n",
    "    StructField(\"nat\", StringType())\n",
    "])\n",
    "\n",
    "# Parse JSON data using the defined schema\n",
    "parsedStreamDF = kafka_source.selectExpr(\"CAST(value AS STRING) as json\") \\\n",
    "    .select(from_json(col(\"json\"), json_schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\")\n",
    "\n",
    "# 1. Build Full Name\n",
    "parsedStreamDF = parsedStreamDF.withColumn(\"full_name\", concat_ws(\" \", \"name.title\", \"name.first\", \"name.last\"))\n",
    "\n",
    "# 2. Calculate Age\n",
    "parsedStreamDF = parsedStreamDF.withColumn(\"calculated_age\", year(current_date()) - year(to_date(\"dob.date\")))\n",
    "\n",
    "# 3. Build Complete Address\n",
    "parsedStreamDF = parsedStreamDF.withColumn(\"complete_address\", concat_ws(\", \", \"location.street.number\", \"location.street.name\", \"location.city\", \"location.state\", \"location.country\", \"location.postcode\"))\n",
    "\n",
    "# 4. Delete the old columns\n",
    "parsedStreamDF = parsedStreamDF.drop(\"name.title\", \"name.first\", \"name.last\", \"location.street.number\", \"location.street.name\", \"location.city\", \"location.state\", \"location.country\", \"location.postcode\")\n",
    "\n",
    "# # Define the Cassandra cluster\n",
    "# cluster = Cluster(['localhost'],port=9042)\n",
    "# session = cluster.connect()\n",
    "\n",
    "# # Define the keyspace name\n",
    "# keyspace = \"user_profiles\"\n",
    "\n",
    "# # Define the table name\n",
    "# table_name = \"Users\"\n",
    "\n",
    "# # Function to save DataFrame to Cassandra\n",
    "# def save_to_cassandra(df, keyspace, table_name):\n",
    "#     # Save the DataFrame to Cassandra\n",
    "#     df.writeStream \\\n",
    "#         .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "#         .outputMode(\"append\") \\\n",
    "#         .options(keyspace=keyspace, table=table_name) \\\n",
    "#         .save()\n",
    "\n",
    "# Define the streaming query\n",
    "parsedStreamDF.writeStream.format('console').start().awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b40d9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
